Metadata-Version: 2.4
Name: litscout
Version: 0.1.0
Summary: LitScout (Literature Scout) MVP-1
Author: LitScout
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: typer>=0.12
Requires-Dist: httpx>=0.27
Requires-Dist: pydantic>=2.6
Requires-Dist: pytest>=8.0
Provides-Extra: dev
Requires-Dist: ruff>=0.4; extra == "dev"

# LitScout (Literature Scout) â€” MVP-1

LitScout is a lightweight research tooling CLI that searches papers from arXiv and Semantic Scholar, normalizes and deduplicates results, and persists them to Markdown, JSONL, and a SQLite database.

## Installation

```bash
pip install -e .
```

## Environment Variables

- `S2_API_KEY`: Semantic Scholar Graph API key. If missing, LitScout will warn and continue using arXiv only.

## CLI Usage

```bash
litscout search "graph neural networks" --topk 5 --since 2020
```

Common options:
- `--topk`: Max results per source (default: 100)
- `--since`: Filter by year >= since
- `--out-md`: Output Markdown path (default: `results_raw.md`)
- `--out-jsonl`: Output JSONL path (default: `results_raw.jsonl`)
- `--db`: SQLite database path (default: `~/.litscout/litscout.db`)
- `--no-cache`: Ignore cached results (still writes fresh cache)
- `--max-requests-per-second`: Global request rate limit (default: 0.3333)
- `--out-md`: Output Markdown path (default: output-<timestamp>/results_raw.md)
- `--out-jsonl`: Output JSONL path (default: output-<timestamp>/results_raw.jsonl)
- `--strict`: Disable title-based deduplication (only DOI/arXiv matches)
- `--cache-ttl-seconds`: Cache TTL in seconds (default: 86400)
- `--cache-max-entries`: Max cache entries (default: 2000)
- `--log-level`: Log level (DEBUG, INFO, WARNING, ERROR)

## Output Formats

1) **Markdown (RAW)**
- Human-readable report of normalized papers with source records and dedup notes.

2) **JSONL**
- One canonical paper per line, fully serialized with authors and sources.

3) **SQLite**
- Entity storage with `papers`, `authors`, `paper_authors`, and `sources` tables.
- Includes a simple cache table for API responses.

## Rate Limiting & Retries

- A shared async rate limiter controls requests across arXiv and Semantic Scholar.
- Failed requests are retried up to 2 times with exponential backoff.

## Cache Cleanup

You can manually clean the cache to enforce TTL or size caps:

```bash
litscout cache-cleanup --cache-ttl-seconds 86400 --cache-max-entries 2000
```

## Extending to New Sources

Add a new connector under `src/litscout/connectors/`, normalize results into the
`CanonicalPaper` model, and include it in `cli.py`. The deduper and storage
layers will work with any source that follows the canonical model.
